- After the last transformer layer, each token (or each student) has a contextualized backpack:
  - Token A knows about B & C.
  - Token B knows about A & C.
  - Token C knows about A & B.

So you end up with one vector per token position.
But many tasks (like sentiment analysis, similarity search, question-answer matching) need just one vector per sentence.

That’s where pooling comes in.

## Pooling strategies

### Mean Pooling (the average student backpack)

- Everyone empties their backpacks onto the desk.
- We mix everything together, divide by number of students.
- Result = “the average knowledge of the whole class.”

Mathematically:

$$
\text{SentenceVec} = \frac{1}{N} \sum_{i=1}^{N} t_i
$$

If a sentence has N tokens (words),
​
Now we want **one sentence vector** (class knowledge) from these three students.

As our final result from previous processing is `Z`

```js
Z ≈ [
  [1.30, 0.68],   // A’s updated info
  [1.30, 0.68],   // B’s updated info
  [1.30, 0.67],   // C’s updated info
];

```

Using **Mean Pooling**:

$$
\text{SentenceVec} = \frac{1}{3} \Big( [1.30, 0.68] + [1.30, 0.68] + [1.30, 0.67] \Big)
$$

which gives us

```js
SentenceVec = [1.3, 0.68];
```

- Every student’s updated info is averaged.
- The class as a whole is now represented by a single vector

### CLS Pooling

1. Setup

- Before class starts, we add a special student called [CLS] (short for “classification” token).
- This student doesn’t bring their own backpack initially (it starts as an empty placeholder vector).
- Their job: sit in class, listen to everyone, and take the official notes.

2. During Attention

- Just like A, B, and C, the [CLS] token attends to all the students’ discussions.
- But unlike A, B, and C, we don’t care about updating A, B, C’s backpacks anymore.
- Instead, we only care about what [CLS] wrote in its notebook (its final vector after the transformer layers).

3. After Class

- While Mean Pooling averages everyone’s backpacks…
- In CLS Pooling, we just say:

  “The class rep [CLS] has the official notes, so we’ll use that.”

So the sentence vector = [CLS]’s final embedding.
